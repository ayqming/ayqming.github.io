<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Proxmox VE集群部署配置 | The Expanse</title><meta name="description" content="网络Vlan和bond配置​    因为工作上的原因，需要开始着手研究部署Proxmox VE集群，选择最新的6.2版本。安装PVE的过程很简单，在安装阶段需要输入一个IP地址，注意这个IP必须是要能联通，通过这个地址可以访问https:&#x2F;&#x2F;IP:8006的Web UI管理页面，也可以通过这个IP直接SSH到Debian系统里。 ​    我在网络这一步遇到了第一个坑，先说下设备的物理环境： 几台"><meta name="keywords" content="Proxmox"><meta name="author" content="Ayqming"><meta name="copyright" content="Ayqming"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Proxmox VE集群部署配置"><meta name="twitter:description" content="网络Vlan和bond配置​    因为工作上的原因，需要开始着手研究部署Proxmox VE集群，选择最新的6.2版本。安装PVE的过程很简单，在安装阶段需要输入一个IP地址，注意这个IP必须是要能联通，通过这个地址可以访问https:&#x2F;&#x2F;IP:8006的Web UI管理页面，也可以通过这个IP直接SSH到Debian系统里。 ​    我在网络这一步遇到了第一个坑，先说下设备的物理环境： 几台"><meta name="twitter:image" content="https://i.loli.net/2020/07/15/iNMFKdobAv7axyP.jpg"><meta property="og:type" content="article"><meta property="og:title" content="Proxmox VE集群部署配置"><meta property="og:url" content="http://ayqming.github.io/2020/07/14/proxmox%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"><meta property="og:site_name" content="The Expanse"><meta property="og:description" content="网络Vlan和bond配置​    因为工作上的原因，需要开始着手研究部署Proxmox VE集群，选择最新的6.2版本。安装PVE的过程很简单，在安装阶段需要输入一个IP地址，注意这个IP必须是要能联通，通过这个地址可以访问https:&#x2F;&#x2F;IP:8006的Web UI管理页面，也可以通过这个IP直接SSH到Debian系统里。 ​    我在网络这一步遇到了第一个坑，先说下设备的物理环境： 几台"><meta property="og:image" content="https://i.loli.net/2020/07/15/iNMFKdobAv7axyP.jpg"><meta property="article:published_time" content="2020-07-14T13:41:36.401Z"><meta property="article:modified_time" content="2020-07-21T14:05:52.042Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="http://ayqming.github.io/2020/07/14/proxmox%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"><link rel="next" title="博客配置来必力评论" href="http://ayqming.github.io/2020/07/08/%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%E6%9D%A5%E5%BF%85%E5%8A%9B%E8%AF%84%E8%AE%BA/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">6</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">8</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">5</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa-fw fas fa-comment-dots"></i><span> 留言板</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#网络"><span class="toc-number">1.</span> <span class="toc-text">网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Vlan和bond配置"><span class="toc-number">1.1.</span> <span class="toc-text">Vlan和bond配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#存储"><span class="toc-number">2.</span> <span class="toc-text">存储</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#iscsi配置共享存储"><span class="toc-number">2.1.</span> <span class="toc-text">iscsi配置共享存储</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NFS配置共享目录"><span class="toc-number">2.2.</span> <span class="toc-text">NFS配置共享目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Ceph分布式存储部署"><span class="toc-number">2.3.</span> <span class="toc-text">Ceph分布式存储部署</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://i.loli.net/2020/07/15/iNMFKdobAv7axyP.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">The Expanse</a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa-fw fas fa-comment-dots"></i><span> 留言板</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Proxmox VE集群部署配置</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-07-14 21:41:36"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-07-14</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-07-21 22:05:52"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-07-21</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/">虚拟化</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">3.4k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 11 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><h3 id="Vlan和bond配置"><a href="#Vlan和bond配置" class="headerlink" title="Vlan和bond配置"></a>Vlan和bond配置</h3><p>​    因为工作上的原因，需要开始着手研究部署Proxmox VE集群，选择最新的6.2版本。安装PVE的过程很简单，在安装阶段需要输入一个IP地址，注意这个IP必须是要能联通，通过这个地址可以访问<a href="https://IP:8006的Web">https://IP:8006的Web</a> UI管理页面，也可以通过这个IP直接SSH到Debian系统里。</p>
<p>​    我在网络这一步遇到了第一个坑，先说下设备的物理环境：</p>
<p>几台Dell的物理机，都装有两块光纤网卡，一块连在一组S4810交换机上跑业务，一块连在一组S4810交换机上连接集中存储。业务交换机上划分了4个Vlan，服务器和交换机的口配置的是target。</p>
<p>​    所以在安装系统的时候，我选择了一个用于管理的Vlan网段中的地址，但是安装完成后显然是连不上的，因为PVE系统安装后会自动的生成一个网桥的配置，类似于这种：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">root@node03:~# cat /etc/network/interfaces</span><br><span class="line">    auto lo</span><br><span class="line">    iface lo inet loopback</span><br><span class="line"></span><br><span class="line">    iface eno1 inet manual</span><br><span class="line">    auto vmbr0</span><br><span class="line">    iface vmbr0 inet static</span><br><span class="line">            address 10.200.50.142</span><br><span class="line">            netmask 255.255.255.0</span><br><span class="line">            gateway 10.200.50.254</span><br><span class="line">            bridge_ports eno1</span><br><span class="line">            bridge_stp off</span><br><span class="line">            bridge_fd 0</span><br><span class="line"></span><br><span class="line">    iface eno2 inet manual</span><br><span class="line">    iface eno3 inet manual</span><br><span class="line">    iface eno4 inet manual</span><br></pre></td></tr></table></figure>

<ol>
<li>第一步需要进系统配置加载支持vlan的模块：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">:~# modprobe 8021q</span><br><span class="line">:~# echo "8021q" &gt;&gt; /etc/modules</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>第二步编辑网卡配置文件，重点是在bridge下新增虚拟网卡实现vlan:</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">root@node01:~# cat &#x2F;etc&#x2F;network&#x2F;interfaces</span><br><span class="line"></span><br><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line"></span><br><span class="line">iface eno1 inet manual</span><br><span class="line">iface eno3 inet manual</span><br><span class="line">iface eno4 inet manual</span><br><span class="line">iface enp4s0f1 inet manual</span><br><span class="line"></span><br><span class="line">auto eno2</span><br><span class="line">iface eno2 inet manual</span><br><span class="line">auto enp4s0f0</span><br><span class="line">iface enp4s0f0 inet manual</span><br><span class="line">auto bond0</span><br><span class="line">iface bond0 inet static</span><br><span class="line">        address 172.16.14.173&#x2F;24</span><br><span class="line">        bond-slaves eno2 enp4s0f0</span><br><span class="line">        bond-miimon 100</span><br><span class="line">        bond-mode active-backup</span><br><span class="line">        bond-primary enp4s0f0</span><br><span class="line">        mtu 9000</span><br><span class="line">#iscsi</span><br><span class="line"></span><br><span class="line">auto vmbr0</span><br><span class="line">iface vmbr0 inet manual</span><br><span class="line">        bridge-ports eno1</span><br><span class="line">        bridge-stp off</span><br><span class="line">        bridge-fd 0</span><br><span class="line">        bridge-vlan-aware yes</span><br><span class="line">        bridge-vids 2-4094</span><br><span class="line"></span><br><span class="line">auto vmbr0.555</span><br><span class="line">iface vmbr0.555 inet static</span><br><span class="line">        address 10.1.255.35&#x2F;24</span><br><span class="line">        gateway 10.1.255.254</span><br><span class="line">#Management</span><br><span class="line"></span><br><span class="line">auto vmbr0.301</span><br><span class="line">iface vmbr0.301 inet static</span><br><span class="line">        address 10.10.2.245&#x2F;24</span><br><span class="line">#LAN</span><br><span class="line"></span><br><span class="line">auto vmbr0.300</span><br><span class="line">iface vmbr0.300 inet static</span><br><span class="line">        address 10.10.0.245&#x2F;24</span><br><span class="line">#LAN</span><br><span class="line"></span><br><span class="line">auto vmbr0.547</span><br><span class="line">iface vmbr0.547 inet static</span><br><span class="line">        address 10.10.247.245&#x2F;24</span><br><span class="line">#DMZ</span><br></pre></td></tr></table></figure>

<p>​    上面的配置中包含了两个部分，一个是网卡eno2 和enp4s0f0 组成了一个bond0，配置成主备模式，用来使用iscsi连接存储交换机。<a href="https://blog.51cto.com/linuxnote/1680315" target="_blank" rel="noopener">传送门:7种模式</a></p>
<p>​    下面部分就是网桥vmbr0，以及在该网桥下新建的4个VLAN，注意vmbr0是绑定在eno1上，而IP是配置在网桥下的虚拟网卡里的。这种情况下虚拟机只要配置连接vmbr0，对应的虚拟机网卡里配置不同vlan网段的IP即可联通外面的网络。<br>3. 重启服务<br>​    配置完成后，重启networking.service即可，如果想通过Web UI配置也可以，但是需要系统安装 ifupdown2包来实现web应用配置。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt install ifupdown2</span><br></pre></td></tr></table></figure>
<p>​    关于vlan配置的问题，官方文档说：</p>
<p>VLAN on the Host<br>To allow host communication with an isolated network. It is possible to apply VLAN tags to any network device (NIC, Bond, Bridge). In general, you should configure the VLAN on the interface with the least abstraction layers between itself and the physical NIC.</p>
<p>​    因此按推荐的应该可以直接在eno1的网卡下直接配置虚拟的vlan网卡，然后再在虚拟vlan网卡上起bridge，但是在我的环境下我如此部署测试不成功，所以最终选择了如上的配置。</p>
<p>​    在这种模式下，因为所有的虚拟机都连着一个bridge所以物理上的流量是互通的，但是因为虚拟机各有各的Vlan标签和网段，他们之间是隔离开来的，这个还需要进一步的测试。</p>
<h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2><h3 id="iscsi配置共享存储"><a href="#iscsi配置共享存储" class="headerlink" title="iscsi配置共享存储"></a>iscsi配置共享存储</h3><p>​    因为我后端是一个磁盘阵列，所以可以配置各个服务器通过iscsi连接到存储上，共享一个或多个共享卷。网上的资料不是很多，以下为我摸索后可行的操作。首先保障磁盘阵列这边新建卷和服务器，服务器的bond配置正确可以ping通存储。</p>
<ol>
<li>第一步：安装iscsi包，访问并登陆存储<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apt-get install open-iscsi</span><br><span class="line"><span class="meta">#</span><span class="bash"> 静态发现</span></span><br><span class="line">iscsiadm -m discovery -t sendtargets -p 172.16.14.29:3206</span><br><span class="line"><span class="meta">#</span><span class="bash"> 登陆</span></span><br><span class="line">iscsiadm -m discovery -t st -p 172.16.14.29:3260  --login</span><br><span class="line"><span class="meta">#</span><span class="bash"> 挂载</span></span><br><span class="line">iscsiadm -m node -T iqn.2002-03.com.compellent:5000d31000ae0b55 -p 172.16.14.29:3260,0 -l</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>​    由于我后端存储使用了双控制器多路径，因此挂载时没条路径都要挂载一次，为此专门写了个脚本来在所有服务器上跑：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">iscsiadm -m discovery -t st -p 172.16.14.29:3260 &gt;&gt; iscsi.txt</span><br><span class="line">while read LINE</span><br><span class="line">  do</span><br><span class="line">  iscsi_ip=$(echo $LINE | awk '&#123;print $1&#125;')</span><br><span class="line">  iscsi_name=$(echo $LINE | awk '&#123;print $2&#125;')</span><br><span class="line">  iscsiadm -m node -T $iscsi_name -p $iscsi_ip -l</span><br><span class="line">done &lt; iscsi.txt</span><br></pre></td></tr></table></figure>

<p>​    然后在 /etc/iscsi/initiatorname.iscsi 配置文件里，可以看到本机的iscsi ID，全球唯一哦。利用这个ID可以在存储上添加HBA卡，绑定在之前配置的服务器上，然后将共享卷映射在服务器。</p>
<p>​    使用命令：iscsiadm -m node -R 重新扫描iscsi，然后通过fdisk -l ，就可以看到映射的卷了。</p>
<p>​    这使用前还有一个问题，因为我是通过多路径挂载的，所以会识别多个磁盘路径，在不同服务器自动生成的磁盘路径可能不同，所以使用起来也会有问题，这时候需要进行第二步。</p>
<ol start="2">
<li>第二步：安装multipath，配置多路径<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install multipath-tools</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>​    注意Debian系统的包与centos系列的包不太一样，推荐看下redhat的官方文档 : <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html-single/dm_multipath/index" target="_blank" rel="noopener">DM Multipath</a></p>
<p>然后启动服务 systemctl start multipathd.service</p>
<p>​    启动完成后使用multipath -ll可以看到合并成一块盘了，默认名称可能是mpathb这种，通过修改配置文件可以给盘设置别名方便后面格式化的操作。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/multipath.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 黑名单里的磁盘不参与多路径</span></span><br><span class="line">blacklist &#123;</span><br><span class="line">devnode "^sda"</span><br><span class="line">devnode "^sdb"</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置别名</span></span><br><span class="line">multipaths &#123;</span><br><span class="line">        multipath &#123;</span><br><span class="line">                wwid 36000d31000ae0b000000000000000097</span><br><span class="line">                alias pve35-data01</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p><img src="https://i.loli.net/2020/07/14/nRVgHMcA7rE1PNs.png" alt=""></p>
<ol start="3">
<li>第三步，格式化硬盘创建分区</li>
</ol>
<p>​    使用fdisk来新建分区，注意第一步使用g命令转换为gpt格式，第二步n新建分区，第三步是输入来转换分区格式，输入31对应的是’Linux LVM’格式，可以输入L来看一共有多少种格式和没种格式对应的数字编号，最后输入w完成写入。</p>
<p><img src="https://i.loli.net/2020/07/15/FErJGQR4yXb736P.png" alt="image-20200715221851341"></p>
<p>这时再fdisk -l 就能看到新增的分区了</p>
<p><img src="https://i.loli.net/2020/07/15/QiMHkZPITlO52LE.png" alt="image-20200715221931613"></p>
<ol start="4">
<li>第四步：创建PV和VG</li>
</ol>
<p>​    正常情况下如果是本地磁盘，可以直接在Web UI上存储-LVM的标签里新建LVM卷或者LVM_thin卷。但是iscsi共享的卷识别不出空闲硬盘，在硬盘选项卡里也显示不出来。同时iscsi共享卷不支持LVM_thin格式，这意味这新建虚拟机时分配了多少存储空间，就会直接占用该共享卷多少空间，不能支持超售了！</p>
<p>​    这里遇到了第二个大坑，创建PV的时候一直报错，试过很多办法都不得解，最后还是觉得可能是多路径的原因导致的，因为以上的操作在服务器的一个节点上操作就可以，而我当时在另外一个节点上重复了操作，并且设置多路径别名的时候设置成了相同的。</p>
<p>​    我把别名改成不同的，重新刷新多路径后，就可以创建PV了。</p>
<p><img src="https://i.loli.net/2020/07/15/k8oOeJpDang1xAQ.png" alt=""></p>
<p>​    在一个节点上完成上面的各个步骤以后，就可以在别的节点上依次使用 partprobe命令刷新系统的分区表，应该能看到相同的VG卷。<br>​    刷新完成后在数据中心的存储标签下新建一个共享的LVM了。其实到这一步就能发现，PVE的LVM系统实际上是利用linux系统底层硬盘组成的VG卷，然后划分给虚拟机使用的存储空间是在VG卷上划分出的LV卷。</p>
<p>​    <img src="https://i.loli.net/2020/07/15/khmuGUNslXniVF9.png" alt=" "></p>
<p>​    创建完LVM就可以在上面新建虚拟机，虚拟机支持动态的在节点间迁移。</p>
<ol start="5">
<li><p>第五步，扩容共享LVM的空间</p>
<p>想一次规划完硬盘的容量是不现实的，后期肯定会需要对硬盘进行扩容。扩容的步骤和新建其实差不多，包括以下几步：</p>
</li>
</ol>
<ul>
<li><p>磁盘阵列上扩容存储卷</p>
</li>
<li><p>重新扫描iscsi、重新刷新分区表、重启多路径</p>
</li>
<li><p>使用fdisk命令新增第2个分区</p>
</li>
<li><p>使用vgextend命令扩展VG卷</p>
</li>
<li><p>其他节点使用 partprobe命令刷新分区表</p>
<p>扩展完VG卷后刷新WEB UI，就可以看到LVM已经变成扩容后的容量了。</p>
</li>
</ul>
<h3 id="NFS配置共享目录"><a href="#NFS配置共享目录" class="headerlink" title="NFS配置共享目录"></a>NFS配置共享目录</h3><p>​    因为需要一个共享的目录来存放各种系统的镜像文件以及虚拟机的备份、模板等，PVE系统默认的目录都是在本机的/var/lib/vz下面，空间又小还不支持共享。</p>
<p>​    正好我在其中一个节点有块900的单独硬盘，拿来做NFS共享盘，提供共享目录。注意前面使用的iscsi共享卷只能做LVM，不能做目录来存放文件。步骤如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 新建硬盘分区</span></span><br><span class="line">fdisk /dev/sdb</span><br><span class="line"><span class="meta">#</span><span class="bash"> 格式化文件系统</span></span><br><span class="line">mkfs -t ext4 /dev/sdb1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 挂载到本地目录</span></span><br><span class="line">mkdir /isodata</span><br><span class="line">mount /dev/sdb1  /isodata</span><br><span class="line"><span class="meta">#</span><span class="bash"> 永久挂载</span></span><br><span class="line"> sed -i "/dev/sdb1  /isodata ext4 defaults 0 0"  /etc/fstab</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装NFS服务端</span></span><br><span class="line">apt-get install nfs-common nfs-kernel-server -y</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建共享目录</span></span><br><span class="line">mkdir /isodata/iso</span><br><span class="line">chmod 644 -R /isodata/iso</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置权限</span></span><br><span class="line">sed -i "/isodata/iso  *(rw,sync,no_root_squash,no_subtree_check,insecure)" /etc/exports</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动服务</span></span><br><span class="line">systemctl start nfs-kernel-server</span><br><span class="line">systemctl enable nfs-kernel-server</span><br></pre></td></tr></table></figure>

<p>​    然后就可以在Web UI上添加共享NFS了，NFS支持存放所有类型的文件，其实也是可以作为虚拟机的共享存储，但是考虑到性能和容量，肯定是不如iscsi的共享存储，因此只配置存放ISO镜像和备份文件。</p>
<p><img src="https://i.loli.net/2020/07/15/jfw5bWMJUIrg9HL.png" alt="image-20200715230959742"></p>
<h3 id="Ceph分布式存储部署"><a href="#Ceph分布式存储部署" class="headerlink" title="Ceph分布式存储部署"></a>Ceph分布式存储部署</h3><p>​    还是先说一下环境，有5台Dell的服务器，每台都有7-9块5.5T的硬盘，为了保证这几台服务器组成另外一个PVE的集群，提供共享存储和HA等功能，所以把5台服务器搭一个Ceph的集群。同时这些硬盘型号完全一致且没有做Raid，正合适组成Ceph。</p>
<p>​    部署Ceph可以直接登陆终端使用命令，也可以直接使用Web UI上提供的页面功能，推荐使用Web页面上的。部署前需要做完基础环境的配置，重点是更改官方的企业源，不然安装升级ceph时可能会删除pve 的系统包！</p>
<ol>
<li>节点上安装Ceph</li>
</ol>
<p>​    在节点上点击Ceph选项卡，会提示尚未安装，点击安装即可</p>
<p><img src="https://i.loli.net/2020/07/20/89AJjPLT3UXoMci.png" alt="image-20200720224504234"></p>
<p>​    安装过程中会提示安装200MB左右的包，速度可能会有点慢，耐心等待即可。</p>
<p><img src="https://i.loli.net/2020/07/20/4FohUvSmPCiTaHj.png" alt="image-20200720224615697"></p>
<p>​    安装完成后，会要求选择Ceph的网络，这里需要注意下，如果你独立的存储网络最好，没有的话和业务网络使用一样的也可以。刷新页面后点击Ceph页签，可以看到配置、监视器。OSD等标签都激活了。在所有节点上都安装完毕，确认没有报错失败等问题。</p>
<ol start="2">
<li>配置Ceph</li>
</ol>
<p>​    按照mon、mgr、osd的顺序进行配置。</p>
<p>​    添加监视器mon，最少1个，必须是奇数，我5台服务器的情况下选择3个mon正合适，在监视器页面选择创建。</p>
<p>​    添加管理mgr，最少1个，可以添加多个，但是同时只有1个节点是激活状态，其他是standby，也在监视器页面创建。</p>
<p><img src="https://i.loli.net/2020/07/20/eMki1uEVxWOvclq.png" alt="image-20200720225647496"></p>
<p>​    然后可以创建OSD，OSD可以使用Web UI上创建，也可以使用命令。这里我选择了命令创建，主要是部分硬盘有分区，需要创建前进行格式化操作，此外因为硬盘数量有点多，点击太费事了。</p>
<p>​    所以写了个简单的脚本，每个节点一共有6块盘，先彻底格式化，然后再创建osd，在每个节点上依次跑这个脚本即可。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"></span><br><span class="line">list=(c d e f g h)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="variable">$&#123;list[*]&#125;</span>;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"############## <span class="variable">$x</span>################"</span></span><br><span class="line">    ceph-volume lvm zap /dev/sd<span class="variable">$x</span> --destroy</span><br><span class="line">    pveceph osd create /dev/sd<span class="variable">$x</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"#################################"</span></span><br></pre></td></tr></table></figure>

<p>​    创建完成的大概是这样的，osd从0开始，到29正好30个。</p>
<p><img src="https://i.loli.net/2020/07/20/OzMWShPavtKV78D.png" alt="image-20200720231307777"></p>
<ol start="3">
<li>创建pool</li>
</ol>
<p>​    pool的整体概念就不细说了，在创建的时候，有两个参数需要注意，副本数（下图中的大小代表最大/小副本数）和pg_num。副本数就是数据会保存几份，主要一个副本要占用额外的一倍空间。pg_num是ceph的逻辑存储单元，每个PG的数据会分散到多个osd上。如果这个Target PGs per OSD的值太小，小于30，集群会一直处于不健康的状态。</p>
<p>​    按照官方文档，如果osd不会发生大的扩展，这个值按100来算，由此可以反推出pg_num。注意这个值必须是2的N次幂，不然同样会报错，我这里选择1024来创建一个pool。</p>
<p><img src="https://i.loli.net/2020/07/20/wmRTFnZLar5YqQz.png" alt="image-20200720233750174"></p>
<ol start="4">
<li>创建RBD</li>
</ol>
<p>最后一步比较简单，在集群目录下，点击存储标签，创建一个RBD类型的共享存储即可。选择在刚才创建的pool上添加。然后在创建虚拟机时就可以使用RBD存储了。RDB支持共享、精简、快照等功能。</p>
<p><img src="https://i.loli.net/2020/07/20/btz5gJZxljYQfGk.png" alt="image-20200720234024691"></p>
<p>使用Ceph以后，也可以使用CephFS，目前我还没有测试这个文件系统，后续如果使用了再补充。</p>
<p>​    </p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Ayqming</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://ayqming.github.io/2020/07/14/proxmox%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/">http://ayqming.github.io/2020/07/14/proxmox%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://ayqming.github.io" target="_blank">The Expanse</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Proxmox/">Proxmox</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/07/15/iNMFKdobAv7axyP.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="next-post pull-full"><a href="/2020/07/08/%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%E6%9D%A5%E5%BF%85%E5%8A%9B%E8%AF%84%E8%AE%BA/"><img class="next_cover" src="https://i.loli.net/2020/05/06/s61JNRwOMaCpoWI.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">博客配置来必力评论</div></div></a></div></nav><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="lv-container" data-id="city" data-uid="MTAyMC81MDk0Ny8yNzQyOQ=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></article></main><footer id="footer" style="background-image: url(https://i.loli.net/2020/07/15/iNMFKdobAv7axyP.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 By Ayqming</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script defer id="ribbon" src="/js/third-party/canvas-ribbon.js" size="100" alpha="0.3" zIndex="-1" mobile="false" data-click="true"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script></body></html>